{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **University of Illinois Chicago**\n",
    "CS 418 - Fall 2024 Team 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data-Driven Course Insights: Predicting Grade Trends**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Authors:**\n",
    "| **Name**  | **Email** | **Github Handle** |\n",
    "|---|---|---|\n",
    "| Arlette Diaz | adiaz218@uic.edu | adiaz218 |\n",
    "| Marianne Hernandez | mhern85@uic.edu | marhern19 |\n",
    "| Nandini Jirobe | njiro2@uic.edu | nandinijirobe |\n",
    "| Sharadruthi Muppidi | smuppi2@uic.edu | sharadruthi-uic |\n",
    "| Sonina Mut | smut3@uic.edu | snina22 |\n",
    "| Yuting Lu | lyuti@uic.edu | yutinglu103 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Github Repository Link: https://github.com/cs418-fa24/project-check-in-team-5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Description**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is to predict course grade distributions and popularity rankings for upcoming semesters, enabling students to make informed decisions about their class selections. By shifting the focus from individual grade predictions to overall course outcomes, the project provides insights into course grading trends and demand. It uses clustering to rank courses based on student performance and popularity, and topic-based grouping to help students discover courses aligned with their interests, factoring in professor expertise and class attributes. This data-driven tool uncovers hidden patterns, aiding both students and academic planning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Update**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Packages**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/anaconda3/lib/python3.12/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/anaconda3/lib/python3.12/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/anaconda3/lib/python3.12/site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: tabulate in /opt/anaconda3/lib/python3.12/site-packages (0.9.0)\n"
     ]
    }
   ],
>>>>>>> a726c22 (updated display for dataset 2 RMP)
   "source": [
    "import sys\n",
    "python_loc = sys.executable\n",
    "\n",
    "!{python_loc} -m pip install pandas\n",
    "!{python_loc} -m pip install scikit-learn\n",
    "!{python_loc} -m pip install matplotlib\n",
    "!{python_loc} -m pip install seaborn\n",
    "!{python_loc} -m pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 2,
>>>>>>> a726c22 (updated display for dataset 2 RMP)
   "metadata": {},
   "outputs": [],
   "source": [
    "# import useful libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Dict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "import urllib3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# from tabulate import tabulate # 'pip install tabulate' if you haven't install this library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 1: Load Datasets**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 3,
>>>>>>> a726c22 (updated display for dataset 2 RMP)
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade distribution data \n",
    "cs_grades = pd.read_csv('uic_GD_CS_14_24.csv')\n",
    "meie_grades = pd.read_csv('uic_GD_MEIE_14_24.csv')\n",
    "\n",
    "# Rate My Professor Data\n",
    "cs_rmp = pd.read_csv('uic_RMP_CS_14_24.csv')\n",
    "meie_rmp = pd.read_csv('CS418_Team5_DataSet - RMP_MEIE_14_24.csv')\n",
    "\n",
    "# Google Scholar Data\n",
    "cs_gs = pd.read_csv('CS418_Team5_DataSet - GS_CS_14_24.csv')\n",
    "meie_gs = pd.read_csv('CS418_Team5_DataSet - GS_MEIE_14_24.csv')\n",
    "\n",
    "# Lecture Data\n",
    "cs_lectures = pd.read_csv('uic_CS_lectures_all_semesters.csv')\n",
    "me_lectures = pd.read_csv('uic_ME_lectures_all_semesters.csv')\n",
    "ie_lectures = pd.read_csv('uic_IE_lectures_all_semesters.csv')\n",
    "\n",
    "# Course Description Data\n",
    "cs_descrip = pd.read_csv('CS418_Team5_DataSet - CS_Descrip.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course Code</th>\n",
       "      <th>Course Title</th>\n",
       "      <th>CRN</th>\n",
       "      <th>Section Type</th>\n",
       "      <th>Time</th>\n",
       "      <th>Days</th>\n",
       "      <th>Instructor</th>\n",
       "      <th>Method</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CS 100</td>\n",
       "      <td>Discovering Computer Science</td>\n",
       "      <td>17397.0</td>\n",
       "      <td>LCD</td>\n",
       "      <td>02:00 PM - 02:50 PM</td>\n",
       "      <td>MWF</td>\n",
       "      <td>Reed, D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS 107</td>\n",
       "      <td>Introduction to Computing and Programming</td>\n",
       "      <td>17412.0</td>\n",
       "      <td>LEC</td>\n",
       "      <td>12:30 PM - 01:45 PM</td>\n",
       "      <td>TR</td>\n",
       "      <td>Theys, M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CS 109</td>\n",
       "      <td>C/C ++ Programming for Engineers with MatLab</td>\n",
       "      <td>19466.0</td>\n",
       "      <td>LCD</td>\n",
       "      <td>02:00 PM - 02:50 PM</td>\n",
       "      <td>MW</td>\n",
       "      <td>Hummel, J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CS 111</td>\n",
       "      <td>Program Design I</td>\n",
       "      <td>34013.0</td>\n",
       "      <td>LCD</td>\n",
       "      <td>02:00 PM - 03:15 PM</td>\n",
       "      <td>TR</td>\n",
       "      <td>Troy, P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CS 141</td>\n",
       "      <td>Program Design II</td>\n",
       "      <td>34447.0</td>\n",
       "      <td>LCD</td>\n",
       "      <td>01:00 PM - 01:50 PM</td>\n",
       "      <td>MWF</td>\n",
       "      <td>Reed, D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Course Code                                  Course Title      CRN  \\\n",
       "0      CS 100                  Discovering Computer Science  17397.0   \n",
       "1      CS 107     Introduction to Computing and Programming  17412.0   \n",
       "2      CS 109  C/C ++ Programming for Engineers with MatLab  19466.0   \n",
       "3      CS 111                              Program Design I  34013.0   \n",
       "4      CS 141                             Program Design II  34447.0   \n",
       "\n",
       "  Section Type                 Time Days Instructor Method Semester  Year  \n",
       "0          LCD  02:00 PM - 02:50 PM  MWF    Reed, D    NaN   Spring  2014  \n",
       "1          LEC  12:30 PM - 01:45 PM   TR   Theys, M    NaN   Spring  2014  \n",
       "2          LCD  02:00 PM - 02:50 PM   MW  Hummel, J    NaN   Spring  2014  \n",
       "3          LCD  02:00 PM - 03:15 PM   TR    Troy, P    NaN   Spring  2014  \n",
       "4          LCD  01:00 PM - 01:50 PM  MWF    Reed, D    NaN   Spring  2014  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> a726c22 (updated display for dataset 2 RMP)
   "source": [
    "cs_lectures.head(5)\n",
    "\n",
    "# print(cs_lectures['Method'].unique())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 2: Data Cleaning**"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset 1 - Grade Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/1qscgnhj30739tc0ww8j16zc0000gn/T/ipykernel_53263/2082822981.py:12: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  cs_grades[col] = pd.to_numeric(cs_grades[col], errors='ignore')\n",
      "/var/folders/_q/1qscgnhj30739tc0ww8j16zc0000gn/T/ipykernel_53263/2082822981.py:15: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  meie_grades[col] = pd.to_numeric(meie_grades[col], errors='ignore')\n"
     ]
    }
   ],
>>>>>>> a726c22 (updated display for dataset 2 RMP)
   "source": [
    "# Grade distribution data cleaning\n",
    "# Drop columns where all values are zero\n",
    "cs_grades = cs_grades.loc[:, (cs_grades != 0).any(axis=0)]\n",
    "meie_grades = meie_grades.loc[:, (meie_grades != 0).any(axis=0)]\n",
    "\n",
    "# Drop rows where CRS TITLE (course title) contains \"research\" or \"seminar\" (case-insensitive)\n",
    "cs_grades = cs_grades[~cs_grades['CRS TITLE'].str.contains(\"research|seminar\", case=False, na=False)]\n",
    "meie_grades = meie_grades[~meie_grades['CRS TITLE'].str.contains(\"research|seminar\", case=False, na=False)]\n",
    "\n",
    "# Convert all numeric columns to integers or floats\n",
    "for col in cs_grades.columns:\n",
    "    cs_grades[col] = pd.to_numeric(cs_grades[col], errors='ignore')\n",
    "\n",
    "for col in meie_grades.columns:\n",
    "    meie_grades[col] = pd.to_numeric(meie_grades[col], errors='ignore')\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "cs_grades.to_csv(\"uic_GD_CS_14_24.csv\", index=False)\n",
    "meie_grades.to_csv(\"uic_GD_MEIE_14_24.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "#### **Dataset 2.1 - Rate My Professor - Computer Science Department**"
=======
    "#### **Dataset 2 - Rate My Professor - computer Science Department**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cleaning data shows the result of joining two files: a CS grade distribution file (uic_GD_CS_14_24.csv), which contains course details and instructors and a Rate My Professors (RMP) file (uic_RMP_CS_14_24.csv), which includes ratings and the number of reviews for each instructor. Each row represents a record of the course titled along with information about instructors and their ratings."
>>>>>>> a726c22 (updated display for dataset 2 RMP)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRS SUBJ CD  CRS NBR                    CRS TITLE              Instructor Rating Num Reviews\n",
      "         CS      100 Discovering Computer Science            Reed, Dale F    3.5       128.0\n",
      "         CS      100 Discovering Computer Science                       ,    N/A         N/A\n",
      "         CS      100 Discovering Computer Science            Bell, John T    2.5       117.0\n",
      "         CS      100 Discovering Computer Science         Kidane, Ellen G    1.9       108.0\n",
      "         CS      100 Discovering Computer Science   Hogan, Douglas Joseph    2.6        34.0\n",
      "         CS      100 Discovering Computer Science            Reed, Dale F    3.5       128.0\n",
      "         CS      100 Discovering Computer Science            Reed, Dale F    3.5       128.0\n",
      "         CS      100 Discovering Computer Science         Kidane, Ellen G    1.9       108.0\n",
      "         CS      100 Discovering Computer Science          Parker, Kendal    N/A         N/A\n",
      "         CS      100 Discovering Computer Science            Bell, John T    2.5       117.0\n",
      "         CS      100 Discovering Computer Science            Reed, Dale F    3.5       128.0\n",
      "         CS      100 Discovering Computer Science            Bell, John T    2.5       117.0\n",
      "         CS      100 Discovering Computer Science            Reed, Dale F    3.5       128.0\n",
      "         CS      100 Discovering Computer Science            Bell, John T    2.5       117.0\n",
      "         CS      100 Discovering Computer Science            Reed, Dale F    3.5       128.0\n",
      "         CS      100 Discovering Computer Science            Reed, Dale F    3.5       128.0\n",
      "         CS      100 Discovering Computer Science Reckinger, Shanon Marie    2.9        98.0\n",
      "         CS      100 Discovering Computer Science          Parker, Kendal    N/A         N/A\n",
      "         CS      100 Discovering Computer Science   Hogan, Douglas Joseph    2.6        34.0\n",
      "         CS      100 Discovering Computer Science            Reed, Dale F    3.5       128.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cs_grades.rename(columns={'Primary Instructor': 'Instructor'}, inplace=True)\n",
    "\n",
    "# Filter for courses\n",
    "cs_grades = cs_grades[cs_grades['CRS NBR'].between(100, 599)]\n",
    "\n",
    "merged_data = pd.merge(cs_grades, cs_rmp, on='Instructor', how='left')\n",
    "\n",
    "# Fill missing values with \"N/A\" for NULL columns\n",
    "merged_data['Rating'] = merged_data['Rating'].fillna(\"N/A\")\n",
    "merged_data['Num Reviews'] = merged_data['Num Reviews'].fillna(\"N/A\")\n",
    "merged_data[['CRS SUBJ CD', 'CRS TITLE', 'Instructor']] = merged_data[['CRS SUBJ CD', 'CRS TITLE', 'Instructor']].fillna(\"N/A\")\n",
    "\n",
    "# Select relevant columns and sort by course number (CRS NBR)\n",
    "result_data = merged_data[['CRS SUBJ CD', 'CRS NBR', 'CRS TITLE', 'Instructor', 'Rating', 'Num Reviews']]\n",
    "result_data = result_data.sort_values(by=['CRS NBR'])\n",
    "\n",
    "# print(tabulate(result_data, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
    "print(result_data.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset 2.2 - Rate My Professor - Mechanical & Industrial Engineering Department**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cleaning data shows the result of joining two files: a MEIE grade distribution file(uic_GD_MEIE_14_24.csv), which contains course details and instructors and a Rate My Professors (RMP) file(CS418_Team5_DataSet - RMP_MEIE_14_24.csv), which includes ratings and the number of reviews for each instructor. Each row represents a record of the course titled along with information about instructors and their ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRS SUBJ CD  CRS NBR                      CRS TITLE           Instructor Rating Num Reviews\n",
      "         IE      118 Energy for Sustainable Society Alonso, Matthew Paul    N/A         N/A\n",
      "         ME      118 Energy for Sustainable Society Alonso, Matthew Paul    N/A         N/A\n",
      "         IE      201          Financial Engineering   Banerjee, Prashant    1.8          10\n",
      "         IE      201          Financial Engineering     Darabi, Houshang    3.3          28\n",
      "         IE      201          Financial Engineering     Haghighi, Azadeh    4.8           6\n",
      "         IE      201          Financial Engineering   Banerjee, Prashant    1.8          10\n",
      "         IE      201          Financial Engineering           Hu, Mengqi    2.2          12\n",
      "         IE      201          Financial Engineering     Darabi, Houshang    3.3          28\n",
      "         IE      201          Financial Engineering     Haghighi, Azadeh    4.8           6\n",
      "         IE      201          Financial Engineering      Anahideh, Hadis    2.5           4\n",
      "         IE      201          Financial Engineering     Darabi, Houshang    3.3          28\n",
      "         IE      201          Financial Engineering           Hu, Mengqi    2.2          12\n",
      "         IE      201          Financial Engineering     Darabi, Houshang    3.3          28\n",
      "         IE      201          Financial Engineering   Banerjee, Prashant    1.8          10\n",
      "         IE      201          Financial Engineering     Darabi, Houshang    3.3          28\n",
      "         IE      201          Financial Engineering     Darabi, Houshang    3.3          28\n",
      "         IE      201          Financial Engineering      Anahideh, Hadis    2.5           4\n",
      "         IE      201          Financial Engineering     Darabi, Houshang    3.3          28\n",
      "         IE      201          Financial Engineering     Haghighi, Azadeh    4.8           6\n",
      "         IE      201          Financial Engineering   Banerjee, Prashant    1.8          10\n"
     ]
    }
   ],
   "source": [
    "meie_grades.rename(columns={'Primary Instructor': 'Instructor'}, inplace=True)\n",
    "\n",
    "# Filter for courses\n",
    "meie_grades = meie_grades[meie_grades['CRS NBR'].between(100, 599)]\n",
    "\n",
    "merged_data = pd.merge(meie_grades, meie_rmp, on='Instructor', how='left')\n",
    "\n",
    "# Fill missing values with \"N/A\" for Null columns\n",
    "merged_data['Rating'] = merged_data['Rating'].fillna(\"N/A\")\n",
    "merged_data['Num Reviews'] = merged_data['Num Reviews'].fillna(\"N/A\")\n",
    "merged_data[['CRS SUBJ CD', 'CRS TITLE', 'Instructor']] = merged_data[['CRS SUBJ CD', 'CRS TITLE', 'Instructor']].fillna(\"N/A\")\n",
    "\n",
    "# Select relevant columns then sort them by course number\n",
    "result_data = merged_data[['CRS SUBJ CD', \n",
    "                           'CRS NBR', \n",
    "                           'CRS TITLE', \n",
    "                           'Instructor', \n",
    "                           'Rating', \n",
    "                           'Num Reviews']]\n",
    "result_data = result_data.sort_values(by=['CRS NBR'])\n",
    "\n",
    "# print(tabulate(result_data, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
    "print(result_data.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset 3 - Class Scheduler Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable SSL verification warnings\n",
    "urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "class LectureScheduleScraper:\n",
    "    def __init__(self, semester: str, year: int):\n",
    "        \"\"\"\n",
    "        Initialize the scraper with semester info and determine correct URL format\n",
    "        \n",
    "        Args:\n",
    "            semester (str): Semester name\n",
    "            year (int): Year\n",
    "        \"\"\"\n",
    "        self.semester = semester\n",
    "        self.year = year\n",
    "        self.url = self._get_url_for_semester()\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        })\n",
    "\n",
    "    def _get_url_for_semester(self) -> str:\n",
    "        \"\"\"\n",
    "        Determine the correct URL format based on semester and year\n",
    "        Returns appropriate URL string\n",
    "        \"\"\"\n",
    "        base_url = \"https://webcs7.osss.uic.edu/schedule-of-classes/archive/pre-proof/{}-{}/CS.{}\"\n",
    "        \n",
    "        # Convert semester/year to a comparable date\n",
    "        semester_date = pd.Timestamp(year=self.year, \n",
    "                                   month={\"Spring\": 1, \"Summer\": 6, \"Fall\": 9}[self.semester],\n",
    "                                   day=1)\n",
    "        \n",
    "        # Cutoff date: Spring 2020\n",
    "        cutoff_date = pd.Timestamp(year=2020, month=1, day=1)\n",
    "        \n",
    "        # Use .html for Spring 2020 and later, .htm for earlier dates\n",
    "        extension = \"html\" if semester_date >= cutoff_date else \"htm\"\n",
    "        \n",
    "        return base_url.format(self.semester.lower(), self.year, extension)\n",
    "\n",
    "    def fetch_page(self, max_retries: int = 3) -> str:\n",
    "        \"\"\"\n",
    "        Fetch the webpage content with retry logic\n",
    "        \"\"\"\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = self.session.get(self.url, verify=False, timeout=10)\n",
    "                response.raise_for_status()\n",
    "                return response.text\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    raise Exception(f\"Failed to fetch page after {max_retries} attempts\") from e\n",
    "\n",
    "    def parse_old_format(self, soup: BeautifulSoup) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Parse the old .htm format schedule (pre-2020)\n",
    "        \"\"\"\n",
    "        courses = []\n",
    "        current_course = None\n",
    "        \n",
    "        # Find all paragraph tags\n",
    "        paragraphs = soup.find_all(['p', 'table'])\n",
    "        \n",
    "        for element in paragraphs:\n",
    "            if element.name == 'p':\n",
    "                # Check if this is a course header\n",
    "                # Look for course code pattern like \"IE   201\" or similar\n",
    "                course_info = element.find('a')\n",
    "                if course_info and 'CS' in course_info.text:\n",
    "                    title_parts = element.find_all('b')\n",
    "                    if len(title_parts) >= 3: \n",
    "                        # The course code is in the first bold element, title in second\n",
    "                        course_code = title_parts[0].text.strip()\n",
    "                        course_title = title_parts[2].text.strip()\n",
    "                        \n",
    "                        current_course = {\n",
    "                            'course_code': course_code.replace('\\xa0', ' ').strip(),\n",
    "                            'course_title': course_title,\n",
    "                            'description': element.text.strip(),\n",
    "                            'sections': []\n",
    "                        }\n",
    "                        courses.append(current_course)\n",
    "            \n",
    "            elif element.name == 'table' and current_course:\n",
    "                rows = element.find_all('tr')\n",
    "                for row in rows:\n",
    "                    cols = row.find_all('td')\n",
    "                    if len(cols) >= 9:  # Make sure we have enough columns\n",
    "                        course_type = cols[1].text.strip()\n",
    "                        if course_type.startswith('LEC') or course_type.startswith('LCD'):\n",
    "                            # Combine start and end times\n",
    "                            start_time = cols[3].text.strip()\n",
    "                            end_time = cols[5].text.strip()\n",
    "                            \n",
    "                            # Handle arranged times\n",
    "                            if start_time.upper() == \"ARRANGED\":\n",
    "                                time = \"ARRANGED\"\n",
    "                            else:\n",
    "                                time = f\"{start_time} - {end_time}\" if end_time else start_time\n",
    "                            \n",
    "                            # Clean up CRN and other fields\n",
    "                            crn = cols[0].text.strip().replace('\\xa0', '').replace('strong>', '').strip()\n",
    "                            \n",
    "                            section = {\n",
    "                                'crn': crn,\n",
    "                                'course_type': course_type,\n",
    "                                'time': time,\n",
    "                                'days': cols[6].text.strip(),\n",
    "                                'room': cols[7].text.strip(),\n",
    "                                'building': cols[8].text.strip(),\n",
    "                                'instructor': cols[9].text.strip() if len(cols) > 9 else '',\n",
    "                                'method': '',  # Old format doesn't have method\n",
    "                                'semester': self.semester,\n",
    "                                'year': self.year\n",
    "                            }\n",
    "                            current_course['sections'].append(section)\n",
    "        \n",
    "        # Only return courses that have lecture sections\n",
    "        valid_courses = [course for course in courses if course['sections']]\n",
    "        \n",
    "        if not valid_courses:\n",
    "            print(f\"DEBUG: Found {len(courses)} courses but none had valid lecture sections\")\n",
    "            # Print the first few course codes found to help debug\n",
    "            if courses:\n",
    "                print(\"DEBUG: Found these course codes:\")\n",
    "                for course in courses[:5]:\n",
    "                    print(f\"- {course['course_code']}\")\n",
    "        \n",
    "        return valid_courses\n",
    "\n",
    "\n",
    "    def parse_schedule(self, html_content: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Parse the schedule and extract only lecture sections\n",
    "        Handles both old and new formats\n",
    "        \"\"\"\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        # Check if this is the new format (post-2020)\n",
    "        if soup.find_all('div', class_='row course'):\n",
    "            return self.parse_new_format(soup)\n",
    "        else:\n",
    "            return self.parse_old_format(soup)\n",
    "\n",
    "    def parse_new_format(self, soup: BeautifulSoup) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Parse the new .html format schedule (2020 and later)\n",
    "        \"\"\"\n",
    "        courses = []\n",
    "        course_divs = soup.find_all('div', class_='row course')\n",
    "        \n",
    "        for course_div in course_divs:\n",
    "            course_code = course_div.find('h2').text.strip()\n",
    "            course_title = course_div.find('h3').text.strip()\n",
    "            course_description = course_div.find('p').text.strip()\n",
    "            \n",
    "            table = course_div.find('table')\n",
    "            if not table:\n",
    "                continue\n",
    "                \n",
    "            lecture_sections = []\n",
    "            current_section = None\n",
    "            \n",
    "            for row in table.find_all('tr')[1:]:\n",
    "                cols = row.find_all('td')\n",
    "                if not cols:\n",
    "                    continue\n",
    "                    \n",
    "                if 'separator' in cols[0].get('class', []):\n",
    "                    if current_section:\n",
    "                        current_section['additional_info'] = cols[0].text.strip()\n",
    "                    continue\n",
    "                \n",
    "                course_type = cols[1].text.strip()\n",
    "                if not (course_type.startswith('LEC') or course_type.startswith('LCD')):\n",
    "                    continue\n",
    "                \n",
    "                current_section = {\n",
    "                    'crn': cols[0].text.strip().replace('strong>', ''),\n",
    "                    'course_type': course_type,\n",
    "                    'time': cols[2].text.strip(),\n",
    "                    'days': cols[3].text.strip(),\n",
    "                    'room': cols[4].text.strip(),\n",
    "                    'building': cols[5].text.strip(),\n",
    "                    'instructor': cols[6].text.strip(),\n",
    "                    'method': cols[8].text.strip() if len(cols) > 8 else '',\n",
    "                    'semester': self.semester,\n",
    "                    'year': self.year\n",
    "                }\n",
    "                lecture_sections.append(current_section)\n",
    "            \n",
    "            if lecture_sections:\n",
    "                course_info = {\n",
    "                    'course_code': course_code,\n",
    "                    'course_title': course_title,\n",
    "                    'description': course_description,\n",
    "                    'sections': lecture_sections\n",
    "                }\n",
    "                courses.append(course_info)\n",
    "        \n",
    "        return courses\n",
    "\n",
    "    def create_dataframe(self, courses: List[Dict]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert course data to DataFrame with improved handling and spacing cleanup\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        for course in courses:\n",
    "            for section in course['sections']:\n",
    "                # Clean and standardize fields\n",
    "                crn = section['crn'].replace('\\xa0', '').strip()\n",
    "                course_code = course['course_code'].replace('\\xa0', ' ').strip()\n",
    "                # Compress multiple spaces into single space\n",
    "                course_code = ' '.join(course_code.split())\n",
    "                \n",
    "                # Clean up instructor field - remove extra spaces and quotes\n",
    "                instructor = section['instructor'].strip().strip('\"')\n",
    "                instructor = ' '.join(instructor.split())  # Compress multiple spaces\n",
    "                \n",
    "                # Clean up time field\n",
    "                time = section['time'].strip()\n",
    "                time = ' '.join(time.split())  # Compress multiple spaces\n",
    "                \n",
    "                # Create row with cleaned data\n",
    "                row = {\n",
    "                    'Course Code': course_code,\n",
    "                    'Course Title': course['course_title'].strip(),\n",
    "                    'CRN': crn,\n",
    "                    'Section Type': section['course_type'].strip(),\n",
    "                    'Time': time,\n",
    "                    'Days': section['days'].strip(),\n",
    "                    'Instructor': instructor,\n",
    "                    'Method': section['method'].strip(),\n",
    "                    'Semester': section['semester'].strip(),\n",
    "                    'Year': section['year']\n",
    "                }\n",
    "                rows.append(row)\n",
    "                        \n",
    "        df = pd.DataFrame(rows)\n",
    "        \n",
    "        try:\n",
    "            df['Course Number'] = df['Course Code'].str.extract(r'(\\d+)').astype(float)\n",
    "            df = df.sort_values(['Year', 'Semester', 'Course Number'], na_position='last')\n",
    "            df = df.drop('Course Number', axis=1)\n",
    "        except:\n",
    "            pass\n",
    "                \n",
    "        # Remove any completely empty rows\n",
    "        df = df.dropna(how='all')\n",
    "        \n",
    "        # Convert year to integer\n",
    "        df['Year'] = df['Year'].astype(int)\n",
    "        \n",
    "        return df\n",
    "\n",
    "def main():\n",
    "    semesters = [\n",
    "        ('spring', 2014),\n",
    "        ('summer', 2014),\n",
    "        ('fall', 2014),\n",
    "        ('spring', 2015),\n",
    "        ('summer', 2015),\n",
    "        ('fall', 2015),\n",
    "        ('spring', 2016),\n",
    "        ('summer', 2016),\n",
    "        ('fall', 2016),\n",
    "        ('spring', 2017),\n",
    "        ('summer', 2017),\n",
    "        ('fall', 2017),\n",
    "        ('spring', 2018),\n",
    "        ('summer', 2018),\n",
    "        ('fall', 2018),\n",
    "        ('spring', 2019),\n",
    "        ('summer', 2019),\n",
    "        ('fall', 2019),\n",
    "        ('spring', 2020),\n",
    "        ('summer', 2020),\n",
    "        ('fall', 2020),\n",
    "        ('spring', 2021),\n",
    "        ('summer', 2021),\n",
    "        ('fall', 2021),\n",
    "        ('spring', 2022),\n",
    "        ('summer', 2022),\n",
    "        ('fall', 2022),\n",
    "        ('spring', 2023),\n",
    "        ('summer', 2023),\n",
    "        ('fall', 2023),\n",
    "        ('spring', 2024),\n",
    "        ('summer', 2024),\n",
    "    ]\n",
    "    \n",
    "    successful = []\n",
    "    failed = []\n",
    "    all_data = []\n",
    "\n",
    "    \n",
    "    for season, year in semesters:\n",
    "        try:\n",
    "            semester_name = f\"{season.capitalize()} {year}\"\n",
    "            \n",
    "            scraper = LectureScheduleScraper(season.capitalize(), year)\n",
    "            \n",
    "            courses = scraper.parse_schedule(scraper.fetch_page())\n",
    "            if courses:\n",
    "                df = scraper.create_dataframe(courses)\n",
    "                all_data.append(df)\n",
    "                \n",
    "                successful.append(semester_name)\n",
    "            else:\n",
    "                raise Exception(\"No courses found\")\n",
    "                \n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {semester_name}\")\n",
    "            print(f\"Error details: {str(e)}\")\n",
    "            failed.append((semester_name, str(e)))\n",
    "            print(\"Continuing to next semester...\")\n",
    "            print(\"-\" * 80)\n",
    "            continue\n",
    "    \n",
    "    # Combine all DataFrames and save to a single CSV\n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        output_file = 'uic_CS_lectures_all_semesters.csv' ## change _CS_ to _ME_ or _IE_ for different department, and change code above\n",
    "        combined_df.to_csv(output_file, index=False)\n",
    "        print(f\"\\nSaved combined data to: {output_file}\")\n",
    "    \n",
    "    if successful:\n",
    "        print(\"\\nSuccessfully processed semesters:\")\n",
    "        for semester in successful:\n",
    "            print(f\"- {semester}\")\n",
    "    \n",
    "    if failed:\n",
    "        print(\"\\nFailed semesters:\")\n",
    "        for semester, error in failed:\n",
    "            print(f\"- {semester}: {error}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset 4 - Google Scholar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 3: Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 4: Data Visualizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 5: Machine Learning Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reflection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the hardest part of the project that you’ve encountered so far?**\n",
    "\n",
    "\n",
    "<br>**What are your initial insights?**\n",
    "\n",
    "\n",
    "<br>**Are there any concrete results you can show at this point? If not, why not?**\n",
    "\n",
    "\n",
    "<br>**Going forward, what are the current biggest problems you’re facing?**\n",
    "\n",
    "\n",
    "<br>**Do you think you are on track with your project? If not, what parts do you need to dedicate more time to?**\n",
    "\n",
    "\n",
    "<br>**Given your initial exploration of the data, is it worth proceeding with your project, why? If not, how are you going to change your project and why do you think it’s better than your current results?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Roles/Coordination (important)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arlette Diaz:** \n",
    "* Text\n",
    "\n",
    "<br>**Marianne Hernandez:** \n",
    "* Text\n",
    "\n",
    "<br>**Nandini Jirobe:** \n",
    "* Collected Rate My Professor ratings for professors who taught Mechanical and Industrial Enginnering classes from 2014-2024\n",
    "* Collected Rate My Professor ratings for professors in the Computer Science classes from 2014-2024\n",
    "* Collected Google Scholar research interests of professors who taught Mechanical and Industrial Enginnering classes from 2014-2024\n",
    "* Collected Google Scholar research interests of professors in the Computer Science classes from 2014-2024\n",
    "* Collected course description data for computer science courses taught at UIC. \n",
    "\n",
    "<br>**Sharadruthi Muppidi:** \n",
    "* Text\n",
    "\n",
    "<br>**Sonina Mut:** \n",
    "* Collected UIC Grade Distribution for professors who taught Mechanical and Industrial Enginnering classes from 2014-2024\n",
    "* Collected UIC Grade Distribution for professors in the Computer Science classes from 2014-2024\n",
    "* Collected Rate My Professor ratings for professors who taught Mechanical and Industrial Enginnering classes from 2014-2024\n",
    "* Collected Rate My Professor ratings for professors in the Computer Science classes from 2014-2024\n",
    "\n",
    "<br>**Yuting Lu:** \n",
    "* Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Next Steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
