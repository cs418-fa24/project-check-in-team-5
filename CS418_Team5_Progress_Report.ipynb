{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **University of Illinois Chicago**\n",
    "CS 418 - Fall 2024 Team 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data-Driven Course Insights: Predicting Grade Trends**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Authors:**\n",
    "| **Name**  | **Email** | **Github Handle** |\n",
    "|---|---|---|\n",
    "| Arlette Diaz | adiaz218@uic.edu | adiaz218 |\n",
    "| Marianne Hernandez | mhern85@uic.edu | marhern19 |\n",
    "| Nandini Jirobe | njiro2@uic.edu | nandinijirobe |\n",
    "| Sharadruthi Muppidi | smuppi2@uic.edu | sharadruthi-uic |\n",
    "| Sonina Mut | smut3@uic.edu | snina22 |\n",
    "| Yuting Lu | lyuti@uic.edu | yutinglu103 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Github Repository Link: https://github.com/cs418-fa24/project-check-in-team-5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Description**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is to predict course grade distributions and popularity rankings for upcoming semesters, enabling students to make informed decisions about their class selections. By shifting the focus from individual grade predictions to overall course outcomes, the project provides insights into course grading trends and demand. It uses clustering to rank courses based on student performance and popularity, and topic-based grouping to help students discover courses aligned with their interests, factoring in professor expertise and class attributes. This data-driven tool uncovers hidden patterns, aiding both students and academic planning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Update**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "python_loc = sys.executable\n",
    "\n",
    "!{python_loc} -m pip install pandas\n",
    "!{python_loc} -m pip install scikit-learn\n",
    "!{python_loc} -m pip install matplotlib\n",
    "!{python_loc} -m pip install seaborn\n",
    "!{python_loc} -m pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import useful libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Dict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "import urllib3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from tabulate import tabulate # 'pip install tabulate' if you haven't install this library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 1: Load Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade distribution data \n",
    "cs_grades = pd.read_csv('uic_GD_CS_14_24.csv')\n",
    "meie_grades = pd.read_csv('uic_GD_MEIE_14_24.csv')\n",
    "\n",
    "# Rate My Professor Data\n",
    "cs_rmp = pd.read_csv('uic_RMP_CS_14_24.csv')\n",
    "meie_rmp = pd.read_csv('CS418_Team5_DataSet - RMP_MEIE_14_24.csv')\n",
    "\n",
    "# Google Scholar Data\n",
    "cs_gs = pd.read_csv('CS418_Team5_DataSet - GS_CS_14_24.csv')\n",
    "meie_gs = pd.read_csv('CS418_Team5_DataSet - GS_MEIE_14_24.csv')\n",
    "\n",
    "# Lecture Data\n",
    "cs_lectures = pd.read_csv('uic_CS_lectures_all_semesters.csv')\n",
    "me_lectures = pd.read_csv('uic_ME_lectures_all_semesters.csv')\n",
    "ie_lectures = pd.read_csv('uic_IE_lectures_all_semesters.csv')\n",
    "\n",
    "# Course Description Data\n",
    "cs_descrip = pd.read_csv('CS418_Team5_DataSet - CS_Descrip.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_lectures.head(5)\n",
    "\n",
    "# print(cs_lectures['Method'].unique())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 2: Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset 1 - Grade Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade distribution data cleaning\n",
    "# Drop columns where all values are zero\n",
    "cs_grades = cs_grades.loc[:, (cs_grades != 0).any(axis=0)]\n",
    "meie_grades = meie_grades.loc[:, (meie_grades != 0).any(axis=0)]\n",
    "\n",
    "# Drop rows where CRS TITLE (course title) contains \"research\" or \"seminar\" (case-insensitive)\n",
    "cs_grades = cs_grades[~cs_grades['CRS TITLE'].str.contains(\"research|seminar\", case=False, na=False)]\n",
    "meie_grades = meie_grades[~meie_grades['CRS TITLE'].str.contains(\"research|seminar\", case=False, na=False)]\n",
    "\n",
    "# Convert all numeric columns to integers or floats\n",
    "for col in cs_grades.columns:\n",
    "    cs_grades[col] = pd.to_numeric(cs_grades[col], errors='ignore')\n",
    "\n",
    "for col in meie_grades.columns:\n",
    "    meie_grades[col] = pd.to_numeric(meie_grades[col], errors='ignore')\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "cs_grades.to_csv(\"uic_GD_CS_14_24.csv\", index=False)\n",
    "meie_grades.to_csv(\"uic_GD_MEIE_14_24.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset 2.1 - Rate My Professor - Computer Science Department**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cs_grades.rename(columns={'Primary Instructor': 'Instructor'}, inplace=True)\n",
    "\n",
    "# Filter for courses\n",
    "cs_grades = cs_grades[cs_grades['CRS NBR'].between(100, 599)]\n",
    "\n",
    "merged_data = pd.merge(cs_grades, cs_rmp, on='Instructor', how='left')\n",
    "\n",
    "# Fill missing values with \"N/A\" for NULL columns\n",
    "merged_data['Rating'] = merged_data['Rating'].fillna(\"N/A\")\n",
    "merged_data['Num Reviews'] = merged_data['Num Reviews'].fillna(\"N/A\")\n",
    "merged_data[['CRS SUBJ CD', 'CRS TITLE', 'Instructor']] = merged_data[['CRS SUBJ CD', 'CRS TITLE', 'Instructor']].fillna(\"N/A\")\n",
    "\n",
    "# Select relevant columns and sort by course number (CRS NBR)\n",
    "result_data = merged_data[['CRS SUBJ CD', 'CRS NBR', 'CRS TITLE', 'Instructor', 'Rating', 'Num Reviews']]\n",
    "result_data = result_data.sort_values(by=['CRS NBR'])\n",
    "\n",
    "print(tabulate(result_data, headers='keys', tablefmt='fancy_grid', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset 2.2 - Rate My Professor - Mechanical & Industrial Engineering Department**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meie_grades.rename(columns={'Primary Instructor': 'Instructor'}, inplace=True)\n",
    "\n",
    "# Filter for courses\n",
    "meie_grades = meie_grades[meie_grades['CRS NBR'].between(100, 599)]\n",
    "\n",
    "merged_data = pd.merge(meie_grades, meie_rmp, on='Instructor', how='left')\n",
    "\n",
    "# Fill missing values with \"N/A\" for Null columns\n",
    "merged_data['Rating'] = merged_data['Rating'].fillna(\"N/A\")\n",
    "merged_data['Num Reviews'] = merged_data['Num Reviews'].fillna(\"N/A\")\n",
    "merged_data[['CRS SUBJ CD', 'CRS TITLE', 'Instructor']] = merged_data[['CRS SUBJ CD', 'CRS TITLE', 'Instructor']].fillna(\"N/A\")\n",
    "\n",
    "# Select relevant columns then sort them by course number\n",
    "result_data = merged_data[['CRS SUBJ CD', \n",
    "                           'CRS NBR', \n",
    "                           'CRS TITLE', \n",
    "                           'Instructor', \n",
    "                           'Rating', \n",
    "                           'Num Reviews']]\n",
    "result_data = result_data.sort_values(by=['CRS NBR'])\n",
    "\n",
    "print(tabulate(result_data, headers='keys', tablefmt='fancy_grid', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset 3 - Class Scheduler Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable SSL verification warnings\n",
    "urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "class LectureScheduleScraper:\n",
    "    def __init__(self, semester: str, year: int):\n",
    "        \"\"\"\n",
    "        Initialize the scraper with semester info and determine correct URL format\n",
    "        \n",
    "        Args:\n",
    "            semester (str): Semester name\n",
    "            year (int): Year\n",
    "        \"\"\"\n",
    "        self.semester = semester\n",
    "        self.year = year\n",
    "        self.url = self._get_url_for_semester()\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        })\n",
    "\n",
    "    def _get_url_for_semester(self) -> str:\n",
    "        \"\"\"\n",
    "        Determine the correct URL format based on semester and year\n",
    "        Returns appropriate URL string\n",
    "        \"\"\"\n",
    "        base_url = \"https://webcs7.osss.uic.edu/schedule-of-classes/archive/pre-proof/{}-{}/CS.{}\"\n",
    "        \n",
    "        # Convert semester/year to a comparable date\n",
    "        semester_date = pd.Timestamp(year=self.year, \n",
    "                                   month={\"Spring\": 1, \"Summer\": 6, \"Fall\": 9}[self.semester],\n",
    "                                   day=1)\n",
    "        \n",
    "        # Cutoff date: Spring 2020\n",
    "        cutoff_date = pd.Timestamp(year=2020, month=1, day=1)\n",
    "        \n",
    "        # Use .html for Spring 2020 and later, .htm for earlier dates\n",
    "        extension = \"html\" if semester_date >= cutoff_date else \"htm\"\n",
    "        \n",
    "        return base_url.format(self.semester.lower(), self.year, extension)\n",
    "\n",
    "    def fetch_page(self, max_retries: int = 3) -> str:\n",
    "        \"\"\"\n",
    "        Fetch the webpage content with retry logic\n",
    "        \"\"\"\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = self.session.get(self.url, verify=False, timeout=10)\n",
    "                response.raise_for_status()\n",
    "                return response.text\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    raise Exception(f\"Failed to fetch page after {max_retries} attempts\") from e\n",
    "\n",
    "    def parse_old_format(self, soup: BeautifulSoup) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Parse the old .htm format schedule (pre-2020)\n",
    "        \"\"\"\n",
    "        courses = []\n",
    "        current_course = None\n",
    "        \n",
    "        # Find all paragraph tags\n",
    "        paragraphs = soup.find_all(['p', 'table'])\n",
    "        \n",
    "        for element in paragraphs:\n",
    "            if element.name == 'p':\n",
    "                # Check if this is a course header\n",
    "                # Look for course code pattern like \"IE   201\" or similar\n",
    "                course_info = element.find('a')\n",
    "                if course_info and 'CS' in course_info.text:\n",
    "                    title_parts = element.find_all('b')\n",
    "                    if len(title_parts) >= 3: \n",
    "                        # The course code is in the first bold element, title in second\n",
    "                        course_code = title_parts[0].text.strip()\n",
    "                        course_title = title_parts[2].text.strip()\n",
    "                        \n",
    "                        current_course = {\n",
    "                            'course_code': course_code.replace('\\xa0', ' ').strip(),\n",
    "                            'course_title': course_title,\n",
    "                            'description': element.text.strip(),\n",
    "                            'sections': []\n",
    "                        }\n",
    "                        courses.append(current_course)\n",
    "            \n",
    "            elif element.name == 'table' and current_course:\n",
    "                rows = element.find_all('tr')\n",
    "                for row in rows:\n",
    "                    cols = row.find_all('td')\n",
    "                    if len(cols) >= 9:  # Make sure we have enough columns\n",
    "                        course_type = cols[1].text.strip()\n",
    "                        if course_type.startswith('LEC') or course_type.startswith('LCD'):\n",
    "                            # Combine start and end times\n",
    "                            start_time = cols[3].text.strip()\n",
    "                            end_time = cols[5].text.strip()\n",
    "                            \n",
    "                            # Handle arranged times\n",
    "                            if start_time.upper() == \"ARRANGED\":\n",
    "                                time = \"ARRANGED\"\n",
    "                            else:\n",
    "                                time = f\"{start_time} - {end_time}\" if end_time else start_time\n",
    "                            \n",
    "                            # Clean up CRN and other fields\n",
    "                            crn = cols[0].text.strip().replace('\\xa0', '').replace('strong>', '').strip()\n",
    "                            \n",
    "                            section = {\n",
    "                                'crn': crn,\n",
    "                                'course_type': course_type,\n",
    "                                'time': time,\n",
    "                                'days': cols[6].text.strip(),\n",
    "                                'room': cols[7].text.strip(),\n",
    "                                'building': cols[8].text.strip(),\n",
    "                                'instructor': cols[9].text.strip() if len(cols) > 9 else '',\n",
    "                                'method': '',  # Old format doesn't have method\n",
    "                                'semester': self.semester,\n",
    "                                'year': self.year\n",
    "                            }\n",
    "                            current_course['sections'].append(section)\n",
    "        \n",
    "        # Only return courses that have lecture sections\n",
    "        valid_courses = [course for course in courses if course['sections']]\n",
    "        \n",
    "        if not valid_courses:\n",
    "            print(f\"DEBUG: Found {len(courses)} courses but none had valid lecture sections\")\n",
    "            # Print the first few course codes found to help debug\n",
    "            if courses:\n",
    "                print(\"DEBUG: Found these course codes:\")\n",
    "                for course in courses[:5]:\n",
    "                    print(f\"- {course['course_code']}\")\n",
    "        \n",
    "        return valid_courses\n",
    "\n",
    "\n",
    "    def parse_schedule(self, html_content: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Parse the schedule and extract only lecture sections\n",
    "        Handles both old and new formats\n",
    "        \"\"\"\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        # Check if this is the new format (post-2020)\n",
    "        if soup.find_all('div', class_='row course'):\n",
    "            return self.parse_new_format(soup)\n",
    "        else:\n",
    "            return self.parse_old_format(soup)\n",
    "\n",
    "    def parse_new_format(self, soup: BeautifulSoup) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Parse the new .html format schedule (2020 and later)\n",
    "        \"\"\"\n",
    "        courses = []\n",
    "        course_divs = soup.find_all('div', class_='row course')\n",
    "        \n",
    "        for course_div in course_divs:\n",
    "            course_code = course_div.find('h2').text.strip()\n",
    "            course_title = course_div.find('h3').text.strip()\n",
    "            course_description = course_div.find('p').text.strip()\n",
    "            \n",
    "            table = course_div.find('table')\n",
    "            if not table:\n",
    "                continue\n",
    "                \n",
    "            lecture_sections = []\n",
    "            current_section = None\n",
    "            \n",
    "            for row in table.find_all('tr')[1:]:\n",
    "                cols = row.find_all('td')\n",
    "                if not cols:\n",
    "                    continue\n",
    "                    \n",
    "                if 'separator' in cols[0].get('class', []):\n",
    "                    if current_section:\n",
    "                        current_section['additional_info'] = cols[0].text.strip()\n",
    "                    continue\n",
    "                \n",
    "                course_type = cols[1].text.strip()\n",
    "                if not (course_type.startswith('LEC') or course_type.startswith('LCD')):\n",
    "                    continue\n",
    "                \n",
    "                current_section = {\n",
    "                    'crn': cols[0].text.strip().replace('strong>', ''),\n",
    "                    'course_type': course_type,\n",
    "                    'time': cols[2].text.strip(),\n",
    "                    'days': cols[3].text.strip(),\n",
    "                    'room': cols[4].text.strip(),\n",
    "                    'building': cols[5].text.strip(),\n",
    "                    'instructor': cols[6].text.strip(),\n",
    "                    'method': cols[8].text.strip() if len(cols) > 8 else '',\n",
    "                    'semester': self.semester,\n",
    "                    'year': self.year\n",
    "                }\n",
    "                lecture_sections.append(current_section)\n",
    "            \n",
    "            if lecture_sections:\n",
    "                course_info = {\n",
    "                    'course_code': course_code,\n",
    "                    'course_title': course_title,\n",
    "                    'description': course_description,\n",
    "                    'sections': lecture_sections\n",
    "                }\n",
    "                courses.append(course_info)\n",
    "        \n",
    "        return courses\n",
    "\n",
    "    def create_dataframe(self, courses: List[Dict]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert course data to DataFrame with improved handling and spacing cleanup\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        for course in courses:\n",
    "            for section in course['sections']:\n",
    "                # Clean and standardize fields\n",
    "                crn = section['crn'].replace('\\xa0', '').strip()\n",
    "                course_code = course['course_code'].replace('\\xa0', ' ').strip()\n",
    "                # Compress multiple spaces into single space\n",
    "                course_code = ' '.join(course_code.split())\n",
    "                \n",
    "                # Clean up instructor field - remove extra spaces and quotes\n",
    "                instructor = section['instructor'].strip().strip('\"')\n",
    "                instructor = ' '.join(instructor.split())  # Compress multiple spaces\n",
    "                \n",
    "                # Clean up time field\n",
    "                time = section['time'].strip()\n",
    "                time = ' '.join(time.split())  # Compress multiple spaces\n",
    "                \n",
    "                # Create row with cleaned data\n",
    "                row = {\n",
    "                    'Course Code': course_code,\n",
    "                    'Course Title': course['course_title'].strip(),\n",
    "                    'CRN': crn,\n",
    "                    'Section Type': section['course_type'].strip(),\n",
    "                    'Time': time,\n",
    "                    'Days': section['days'].strip(),\n",
    "                    'Instructor': instructor,\n",
    "                    'Method': section['method'].strip(),\n",
    "                    'Semester': section['semester'].strip(),\n",
    "                    'Year': section['year']\n",
    "                }\n",
    "                rows.append(row)\n",
    "                        \n",
    "        df = pd.DataFrame(rows)\n",
    "        \n",
    "        try:\n",
    "            df['Course Number'] = df['Course Code'].str.extract(r'(\\d+)').astype(float)\n",
    "            df = df.sort_values(['Year', 'Semester', 'Course Number'], na_position='last')\n",
    "            df = df.drop('Course Number', axis=1)\n",
    "        except:\n",
    "            pass\n",
    "                \n",
    "        # Remove any completely empty rows\n",
    "        df = df.dropna(how='all')\n",
    "        \n",
    "        # Convert year to integer\n",
    "        df['Year'] = df['Year'].astype(int)\n",
    "        \n",
    "        return df\n",
    "\n",
    "def main():\n",
    "    semesters = [\n",
    "        ('spring', 2014),\n",
    "        ('summer', 2014),\n",
    "        ('fall', 2014),\n",
    "        ('spring', 2015),\n",
    "        ('summer', 2015),\n",
    "        ('fall', 2015),\n",
    "        ('spring', 2016),\n",
    "        ('summer', 2016),\n",
    "        ('fall', 2016),\n",
    "        ('spring', 2017),\n",
    "        ('summer', 2017),\n",
    "        ('fall', 2017),\n",
    "        ('spring', 2018),\n",
    "        ('summer', 2018),\n",
    "        ('fall', 2018),\n",
    "        ('spring', 2019),\n",
    "        ('summer', 2019),\n",
    "        ('fall', 2019),\n",
    "        ('spring', 2020),\n",
    "        ('summer', 2020),\n",
    "        ('fall', 2020),\n",
    "        ('spring', 2021),\n",
    "        ('summer', 2021),\n",
    "        ('fall', 2021),\n",
    "        ('spring', 2022),\n",
    "        ('summer', 2022),\n",
    "        ('fall', 2022),\n",
    "        ('spring', 2023),\n",
    "        ('summer', 2023),\n",
    "        ('fall', 2023),\n",
    "        ('spring', 2024),\n",
    "        ('summer', 2024),\n",
    "    ]\n",
    "    \n",
    "    successful = []\n",
    "    failed = []\n",
    "    all_data = []\n",
    "\n",
    "    \n",
    "    for season, year in semesters:\n",
    "        try:\n",
    "            semester_name = f\"{season.capitalize()} {year}\"\n",
    "            \n",
    "            scraper = LectureScheduleScraper(season.capitalize(), year)\n",
    "            \n",
    "            courses = scraper.parse_schedule(scraper.fetch_page())\n",
    "            if courses:\n",
    "                df = scraper.create_dataframe(courses)\n",
    "                all_data.append(df)\n",
    "                \n",
    "                successful.append(semester_name)\n",
    "            else:\n",
    "                raise Exception(\"No courses found\")\n",
    "                \n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {semester_name}\")\n",
    "            print(f\"Error details: {str(e)}\")\n",
    "            failed.append((semester_name, str(e)))\n",
    "            print(\"Continuing to next semester...\")\n",
    "            print(\"-\" * 80)\n",
    "            continue\n",
    "    \n",
    "    # Combine all DataFrames and save to a single CSV\n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        output_file = 'uic_CS_lectures_all_semesters.csv' ## change _CS_ to _ME_ or _IE_ for different department, and change code above\n",
    "        combined_df.to_csv(output_file, index=False)\n",
    "        print(f\"\\nSaved combined data to: {output_file}\")\n",
    "    \n",
    "    if successful:\n",
    "        print(\"\\nSuccessfully processed semesters:\")\n",
    "        for semester in successful:\n",
    "            print(f\"- {semester}\")\n",
    "    \n",
    "    if failed:\n",
    "        print(\"\\nFailed semesters:\")\n",
    "        for semester, error in failed:\n",
    "            print(f\"- {semester}: {error}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset 4 - Google Scholar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 3: Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 4: Data Visualizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 5: Machine Learning Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reflection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the hardest part of the project that you’ve encountered so far?**\n",
    "\n",
    "\n",
    "<br>**What are your initial insights?**\n",
    "\n",
    "\n",
    "<br>**Are there any concrete results you can show at this point? If not, why not?**\n",
    "\n",
    "\n",
    "<br>**Going forward, what are the current biggest problems you’re facing?**\n",
    "\n",
    "\n",
    "<br>**Do you think you are on track with your project? If not, what parts do you need to dedicate more time to?**\n",
    "\n",
    "\n",
    "<br>**Given your initial exploration of the data, is it worth proceeding with your project, why? If not, how are you going to change your project and why do you think it’s better than your current results?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Roles/Coordination (important)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arlette Diaz:** \n",
    "* Text\n",
    "\n",
    "<br>**Marianne Hernandez:** \n",
    "* Text\n",
    "\n",
    "<br>**Nandini Jirobe:** \n",
    "* Collected Rate My Professor ratings for professors who taught Mechanical and Industrial Enginnering classes from 2014-2024\n",
    "* Collected Rate My Professor ratings for professors in the Computer Science classes from 2014-2024\n",
    "* Collected Google Scholar research interests of professors who taught Mechanical and Industrial Enginnering classes from 2014-2024\n",
    "* Collected Google Scholar research interests of professors in the Computer Science classes from 2014-2024\n",
    "* Collected course description data for computer science courses taught at UIC. \n",
    "\n",
    "<br>**Sharadruthi Muppidi:** \n",
    "* Text\n",
    "\n",
    "<br>**Sonina Mut:** \n",
    "* Collected UIC Grade Distribution for professors who taught Mechanical and Industrial Enginnering classes from 2014-2024\n",
    "* Collected UIC Grade Distribution for professors in the Computer Science classes from 2014-2024\n",
    "* Collected Rate My Professor ratings for professors who taught Mechanical and Industrial Enginnering classes from 2014-2024\n",
    "* Collected Rate My Professor ratings for professors in the Computer Science classes from 2014-2024\n",
    "\n",
    "<br>**Yuting Lu:** \n",
    "* Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Next Steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
